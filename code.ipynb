{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_excel('data.xlsx')\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "# View the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove timestamp column\n",
    "df = df.drop('Timestamp', axis=1)\n",
    "\n",
    "# Clean column names\n",
    "df.columns = [col.strip() for col in df.columns]\n",
    "df.columns = [col.replace('\\r\\n', '') for col in df.columns]\n",
    "\n",
    "# Check age groups\n",
    "print(\"Unique age groups:\", df['Age Group'].unique())\n",
    "\n",
    "# Clean age groups by removing the word 'years' if present\n",
    "df['Age Group'] = df['Age Group'].str.replace(' years', '')\n",
    "\n",
    "# Fill missing ages based on age group\n",
    "# Define a mapping of age groups to representative ages\n",
    "age_group_mapping = {\n",
    "    '10-19': 17,  # Assuming average of range for those with missing age\n",
    "    '20-29': 25,\n",
    "    '30-39': 35,\n",
    "    '40-49': 45,\n",
    "    '50+': 55\n",
    "}\n",
    "\n",
    "# For each row with missing age, fill with the representative age for its age group\n",
    "for idx, row in df[df['Age'].isna()].iterrows():\n",
    "    age_group = row['Age Group']\n",
    "    if age_group in age_group_mapping:\n",
    "        df.at[idx, 'Age'] = age_group_mapping[age_group]\n",
    "\n",
    "# Count any remaining missing ages\n",
    "missing_ages = df['Age'].isna().sum()\n",
    "print(f\"Remaining missing ages: {missing_ages}\")\n",
    "\n",
    "# View the updated dataframe\n",
    "print(f\"Updated dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values in the entire dataframe\n",
    "null_counts = df.isnull().sum()\n",
    "\n",
    "# Display columns with null values (if any)\n",
    "columns_with_nulls = null_counts[null_counts > 0]\n",
    "if len(columns_with_nulls) > 0:\n",
    "    print(\"Columns with null values:\")\n",
    "    print(columns_with_nulls)\n",
    "else:\n",
    "    print(\"No null values found in the dataset.\")\n",
    "\n",
    "# Get the percentage of null values in each column\n",
    "null_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "\n",
    "# Display columns with null values along with their percentage\n",
    "columns_with_nulls_percentage = null_percentage[null_percentage > 0]\n",
    "if len(columns_with_nulls_percentage) > 0:\n",
    "    print(\"\\nPercentage of null values in columns:\")\n",
    "    print(columns_with_nulls_percentage)\n",
    "    \n",
    "# Count total number of null values in the dataframe\n",
    "total_nulls = df.isnull().sum().sum()\n",
    "print(f\"\\nTotal null values in the dataset: {total_nulls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "\n",
    "# For the column with the most missing values (Family history), replace with 'None reported'\n",
    "df['Family history of diagnosed mental illness in family'].fillna('None reported', inplace=True)\n",
    "\n",
    "# For Likert scale questions (attitude/stigma questions), fill with the mode (most common answer)\n",
    "# First, get a list of all the columns with null values except 'Family history'\n",
    "likert_columns_with_nulls = [col for col in columns_with_nulls.index \n",
    "                            if col != 'Family history of diagnosed mental illness in family']\n",
    "\n",
    "# Fill each column with its mode\n",
    "for col in likert_columns_with_nulls:\n",
    "    mode_value = df[col].mode()[0]\n",
    "    df[col].fillna(mode_value, inplace=True)\n",
    "\n",
    "# Verify all nulls are handled\n",
    "remaining_nulls = df.isnull().sum().sum()\n",
    "print(f\"Remaining null values: {remaining_nulls}\")\n",
    "\n",
    "# If you want to see which columns still have nulls (should be none)\n",
    "if remaining_nulls > 0:\n",
    "    print(df.isnull().sum()[df.isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATSPPHS Openness Subscale (5 items)\n",
    "atspphs_openness = [\n",
    "    'If I believed I was having a mental breakdown, my first inclination would be to get professional help',\n",
    "    'If I were experiencing a serious emotional crisis at this point in my life, I would be confident that I could find relief in psychotherapy',\n",
    "    'I would want to get psychiatric attention if I was worried or upset for a long period of time',\n",
    "    'At some future time, I might want to have psychological counselling',\n",
    "    'A person with an emotional problem is not likely to solve it alone; he is likely to solve with professional help '\n",
    "]\n",
    "\n",
    "# ATSPPHS Value Subscale (5 items)\n",
    "atspphs_value = [\n",
    "    'The idea of talking about problems with a psychologist strikes me as a poor way to get rid of emotional conflicts',\n",
    "    'There is something admirable in the attitude of a person who is willing to deal with own  conflicts and fears without resorting to professional help',\n",
    "    'Considering the time and expense involved in psychotherapy, it would have doubtful value for a person like me',\n",
    "    'A person should work out one\\'s  own problems; getting psychological counselling should be the  last resort',\n",
    "    'Emotional difficulties, like many things, tend to work out by themselves'\n",
    "]\n",
    "\n",
    "# DSS Personal Subscale (9 items)\n",
    "dss_personal = [\n",
    "    'People with depression could snap out of it if they wanted.',\n",
    "    'Depression is a sign of personal weakness',\n",
    "    'Depression is not a real medical illness',\n",
    "    'People with depression are dangerous',\n",
    "    'It is best to avoid people with depression, so you do not become depressed yourself',\n",
    "    'People with depression are unpredictable',\n",
    "    'If I had depression, I would not tell anyone',\n",
    "    'I would not study/mingle with someone if I knew they were  depressed',\n",
    "    'I would not vote for a student for a leadership role if I knew they were  depressed'\n",
    "]\n",
    "\n",
    "# DSS Perceived Subscale (9 items)\n",
    "dss_perceived = [\n",
    "    'Most people believe that people with depression could snap out of it if they wanted',\n",
    "    'Most people believe that depression is a sign of personal weakness',\n",
    "    'Most people believe that depression is not a real medical illness',\n",
    "    'Most people believe that people with depression are dangerous',\n",
    "    'Most people believe it is best to avoid people with depression, so you do not become depressed yourself',\n",
    "    'Most people believe that people with depression are unpredictable',\n",
    "    'If they had depression, most people would not tell anyone',\n",
    "    'Most people would not study/mingle with someone they knew were  depressed',\n",
    "    'Most people would vote for a student for a leadership role who they knew was  depressed'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check exact column names\n",
    "column_names = df.columns.tolist()\n",
    "\n",
    "# Find the exact column names that match our needed items\n",
    "# For ATSPPHS Openness items\n",
    "exact_atspphs_openness = []\n",
    "for item in atspphs_openness:\n",
    "    matches = [col for col in column_names if item.strip() in col.strip()]\n",
    "    if matches:\n",
    "        exact_atspphs_openness.append(matches[0])\n",
    "    else:\n",
    "        print(f\"No match found for: {item}\")\n",
    "\n",
    "# For ATSPPHS Value items\n",
    "exact_atspphs_value = []\n",
    "for item in atspphs_value:\n",
    "    matches = [col for col in column_names if item.strip() in col.strip()]\n",
    "    if matches:\n",
    "        exact_atspphs_value.append(matches[0])\n",
    "    else:\n",
    "        print(f\"No match found for: {item}\")\n",
    "\n",
    "# For DSS Personal items\n",
    "exact_dss_personal = []\n",
    "for item in dss_personal:\n",
    "    matches = [col for col in column_names if item.strip() in col.strip()]\n",
    "    if matches:\n",
    "        exact_dss_personal.append(matches[0])\n",
    "    else:\n",
    "        print(f\"No match found for: {item}\")\n",
    "\n",
    "# For DSS Perceived items\n",
    "exact_dss_perceived = []\n",
    "for item in dss_perceived:\n",
    "    matches = [col for col in column_names if item.strip() in col.strip()]\n",
    "    if matches:\n",
    "        exact_dss_perceived.append(matches[0])\n",
    "    else:\n",
    "        print(f\"No match found for: {item}\")\n",
    "\n",
    "# Print the exact column names found\n",
    "print(\"ATSPPHS Openness items found:\", len(exact_atspphs_openness))\n",
    "print(\"ATSPPHS Value items found:\", len(exact_atspphs_value))\n",
    "print(\"DSS Personal items found:\", len(exact_dss_personal))\n",
    "print(\"DSS Perceived items found:\", len(exact_dss_perceived))\n",
    "\n",
    "# Now use these exact column names for conversion\n",
    "df_numeric = df.copy()\n",
    "\n",
    "# Convert DSS items (higher score = more stigma)\n",
    "df_numeric = convert_likert_to_numeric(df_numeric, exact_dss_personal)\n",
    "df_numeric = convert_likert_to_numeric(df_numeric, exact_dss_perceived)\n",
    "\n",
    "# Check for the last item in perceived stigma that needs to be reversed\n",
    "reversed_item = [col for col in exact_dss_perceived if 'vote for a student' in col]\n",
    "if reversed_item:\n",
    "    likert_mapping = {'Strongly Disagree': 4, 'Disagree': 3, 'Agree': 2, 'Strongly agree': 1, 'Strongly Agree': 1}\n",
    "    df_numeric[reversed_item[0]] = df_numeric[reversed_item[0]].map(likert_mapping)\n",
    "\n",
    "# Convert ATSPPHS items\n",
    "df_numeric = convert_likert_to_numeric(df_numeric, exact_atspphs_openness)\n",
    "df_numeric = convert_likert_to_numeric(df_numeric, exact_atspphs_value, reverse=True)\n",
    "\n",
    "# Calculate scale scores\n",
    "# DSS Personal Scale\n",
    "df_numeric['DSS_Personal'] = df_numeric[exact_dss_personal].sum(axis=1)\n",
    "\n",
    "# DSS Perceived Scale\n",
    "df_numeric['DSS_Perceived'] = df_numeric[exact_dss_perceived].sum(axis=1)\n",
    "\n",
    "# DSS Total Score\n",
    "df_numeric['DSS_Total'] = df_numeric['DSS_Personal'] + df_numeric['DSS_Perceived']\n",
    "\n",
    "# ATSPPHS Openness Scale\n",
    "df_numeric['ATSPPHS_Openness'] = df_numeric[exact_atspphs_openness].sum(axis=1)\n",
    "\n",
    "# ATSPPHS Value Scale\n",
    "df_numeric['ATSPPHS_Value'] = df_numeric[exact_atspphs_value].sum(axis=1)\n",
    "\n",
    "# ATSPPHS Total Score\n",
    "df_numeric['ATSPPHS_Total'] = df_numeric['ATSPPHS_Openness'] + df_numeric['ATSPPHS_Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the full DataFrame columns to examine them\n",
    "print(\"All column names in the DataFrame:\")\n",
    "for i, col in enumerate(df.columns):\n",
    "    print(f\"{i}: {col}\")\n",
    "\n",
    "# Now let's find the closest match for the missing item\n",
    "missing_item = \"A person should work out one's own problems; getting psychological counselling should be the last resort\"\n",
    "potential_matches = [col for col in df.columns if \"work out\" in col and \"psychological\" in col]\n",
    "print(\"\\nPotential matches for the missing item:\")\n",
    "for match in potential_matches:\n",
    "    print(match)\n",
    "\n",
    "# Let's manually fix the ATSPPHS Value list with the correct column name\n",
    "# Assuming we found the match, update the exact_atspphs_value list\n",
    "if potential_matches:\n",
    "    exact_atspphs_value.append(potential_matches[0])\n",
    "    print(f\"\\nAdded missing item: {potential_matches[0]}\")\n",
    "else:\n",
    "    print(\"\\nNo match found. Check your column names carefully.\")\n",
    "\n",
    "print(\"\\nATSPPHS Value items found now:\", len(exact_atspphs_value))\n",
    "\n",
    "# Now recalculate the ATSPPHS Value and Total scores\n",
    "if len(exact_atspphs_value) == 5:  # Only proceed if we have all 5 items\n",
    "    df_numeric = convert_likert_to_numeric(df_numeric, [potential_matches[0]], reverse=True)\n",
    "    df_numeric['ATSPPHS_Value'] = df_numeric[exact_atspphs_value].sum(axis=1)\n",
    "    df_numeric['ATSPPHS_Total'] = df_numeric['ATSPPHS_Openness'] + df_numeric['ATSPPHS_Value']\n",
    "    print(\"Recalculated ATSPPHS scores successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate descriptive statistics for continuous variables\n",
    "continuous_vars = ['Age', 'DSS_Personal', 'DSS_Perceived', 'DSS_Total', 'ATSPPHS_Openness', 'ATSPPHS_Value', 'ATSPPHS_Total']\n",
    "\n",
    "# Create a function to calculate mean and standard deviation\n",
    "def mean_std(data):\n",
    "    return f\"{data.mean():.2f} ± {data.std():.2f}\"\n",
    "\n",
    "# Calculate descriptive statistics\n",
    "desc_stats = pd.DataFrame({\n",
    "    'Mean ± SD': [mean_std(df_numeric[var]) for var in continuous_vars]\n",
    "}, index=continuous_vars)\n",
    "\n",
    "print(\"Descriptive Statistics for Continuous Variables:\")\n",
    "print(desc_stats)\n",
    "\n",
    "# Now let's calculate frequencies and percentages for categorical variables\n",
    "categorical_vars = ['Gender', 'Age Group', 'Field of Study', 'Living arrangement', 'Marital status', \n",
    "                   'Family system', 'History of suicide in family', 'Depression', 'GAD', 'Panic', \n",
    "                   'Schiz', 'Bipolar', 'None']\n",
    "\n",
    "# Calculate frequencies and percentages\n",
    "print(\"\\nFrequency and Percentage for Categorical Variables:\")\n",
    "for var in categorical_vars:\n",
    "    freq = df[var].value_counts()\n",
    "    perc = df[var].value_counts(normalize=True) * 100\n",
    "    print(f\"\\n{var}:\")\n",
    "    result = pd.DataFrame({\n",
    "        'Frequency': freq,\n",
    "        'Percentage (%)': perc.round(1)\n",
    "    })\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's check the data types of our columns\n",
    "print(\"Data types of continuous variables:\")\n",
    "for var in continuous_vars:\n",
    "    if var in df_numeric.columns:\n",
    "        print(f\"{var}: {df_numeric[var].dtype}\")\n",
    "    else:\n",
    "        print(f\"{var}: Not found in dataframe\")\n",
    "\n",
    "# Let's focus on 'Age' first which should be numeric\n",
    "print(\"\\nFirst few values of Age:\")\n",
    "print(df_numeric['Age'].head())\n",
    "\n",
    "# Let's check if all our scale scores are calculated properly\n",
    "# Let's look at the data types of the first few items in each scale\n",
    "print(\"\\nFirst item in DSS Personal:\")\n",
    "if exact_dss_personal:\n",
    "    print(f\"{exact_dss_personal[0]}: {df_numeric[exact_dss_personal[0]].dtype}\")\n",
    "    print(df_numeric[exact_dss_personal[0]].head())\n",
    "\n",
    "print(\"\\nFirst item in DSS Perceived:\")\n",
    "if exact_dss_perceived:\n",
    "    print(f\"{exact_dss_perceived[0]}: {df_numeric[exact_dss_perceived[0]].dtype}\")\n",
    "    print(df_numeric[exact_dss_perceived[0]].head())\n",
    "\n",
    "print(\"\\nFirst item in ATSPPHS Openness:\")\n",
    "if exact_atspphs_openness:\n",
    "    print(f\"{exact_atspphs_openness[0]}: {df_numeric[exact_atspphs_openness[0]].dtype}\")\n",
    "    print(df_numeric[exact_atspphs_openness[0]].head())\n",
    "\n",
    "print(\"\\nFirst item in ATSPPHS Value:\")\n",
    "if exact_atspphs_value:\n",
    "    print(f\"{exact_atspphs_value[0]}: {df_numeric[exact_atspphs_value[0]].dtype}\")\n",
    "    print(df_numeric[exact_atspphs_value[0]].head())\n",
    "\n",
    "# Let's manually recalculate the scale scores to ensure they're numeric\n",
    "# First, make sure our Likert responses are properly converted to numbers\n",
    "print(\"\\nChecking if Likert conversion worked properly:\")\n",
    "for col in exact_dss_personal[:1] + exact_dss_perceived[:1] + exact_atspphs_openness[:1] + exact_atspphs_value[:1]:\n",
    "    unique_values = df_numeric[col].unique()\n",
    "    print(f\"{col}: {unique_values}\")\n",
    "\n",
    "# Let's manually convert one item from each scale to check\n",
    "test_cols = [\n",
    "    exact_dss_personal[0],\n",
    "    exact_dss_perceived[0],\n",
    "    exact_atspphs_openness[0],\n",
    "    exact_atspphs_value[0]\n",
    "]\n",
    "\n",
    "# Define the mapping again\n",
    "likert_mapping = {\n",
    "    'Strongly Disagree': 1, \n",
    "    'Disagree': 2, \n",
    "    'Agree': 3, \n",
    "    'Strongly agree': 4,\n",
    "    'Strongly Agree': 4\n",
    "}\n",
    "\n",
    "# Apply mapping to test columns\n",
    "for col in test_cols:\n",
    "    df_numeric[f\"{col}_test\"] = df_numeric[col].map(likert_mapping)\n",
    "    print(f\"\\nConverted {col}:\")\n",
    "    print(f\"Original: {df_numeric[col].head()}\")\n",
    "    print(f\"Converted: {df_numeric[f'{col}_test'].head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check problematic Age values\n",
    "print(\"Examining Age column:\")\n",
    "print(df_numeric['Age'].value_counts().head(10))  # Show most common values\n",
    "print(\"\\nNon-numeric values in Age column:\")\n",
    "non_numeric = [val for val in df_numeric['Age'].unique() if not pd.api.types.is_numeric_dtype(type(val)) and not isinstance(val, (int, float))]\n",
    "for val in non_numeric:\n",
    "    print(val)\n",
    "\n",
    "# Handle Age with a function to extract just the first number\n",
    "def extract_first_number(age_str):\n",
    "    if pd.isna(age_str):\n",
    "        return np.nan\n",
    "    \n",
    "    if isinstance(age_str, (int, float)):\n",
    "        return age_str\n",
    "    \n",
    "    # Convert to string if it's not already\n",
    "    age_str = str(age_str)\n",
    "    \n",
    "    # Extract the first number from the string\n",
    "    import re\n",
    "    numbers = re.findall(r'\\d+', age_str)\n",
    "    if numbers:\n",
    "        return int(numbers[0])\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Apply the function to Age\n",
    "df_numeric['Age'] = df_numeric['Age'].apply(extract_first_number)\n",
    "print(\"\\nAge after extraction:\", df_numeric['Age'].dtype)\n",
    "print(df_numeric['Age'].value_counts().head(10))\n",
    "\n",
    "# Now let's convert to numeric\n",
    "df_numeric['Age'] = pd.to_numeric(df_numeric['Age'], errors='coerce')\n",
    "print(\"\\nAge dtype after conversion:\", df_numeric['Age'].dtype)\n",
    "\n",
    "# Calculate descriptive statistics\n",
    "continuous_vars = ['Age', 'DSS_Personal', 'DSS_Perceived', 'DSS_Total', 'ATSPPHS_Openness', 'ATSPPHS_Value', 'ATSPPHS_Total']\n",
    "\n",
    "# Create a function to calculate mean and standard deviation for numeric data\n",
    "def mean_std(data):\n",
    "    return f\"{data.mean():.2f} ± {data.std():.2f}\"\n",
    "\n",
    "# Calculate descriptive statistics\n",
    "desc_stats = {}\n",
    "for var in continuous_vars:\n",
    "    if var in df_numeric.columns:\n",
    "        desc_stats[var] = mean_std(df_numeric[var])\n",
    "    else:\n",
    "        desc_stats[var] = \"Not calculated\"\n",
    "\n",
    "# Convert to DataFrame for display\n",
    "desc_stats_df = pd.DataFrame({'Mean ± SD': desc_stats}, index=list(desc_stats.keys()))\n",
    "\n",
    "print(\"\\nDescriptive Statistics for Continuous Variables:\")\n",
    "print(desc_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate frequencies and percentages for categorical variables\n",
    "categorical_vars = ['Gender', 'Age Group', 'Field of Study', 'Living arrangement', 'Marital status', \n",
    "                   'Family system', 'History of suicide in family', 'Depression', 'GAD', 'Panic', \n",
    "                   'Schiz', 'Bipolar', 'None']\n",
    "\n",
    "print(\"\\nFrequency and Percentage for Categorical Variables:\")\n",
    "for var in categorical_vars:\n",
    "    if var in df.columns:\n",
    "        freq = df[var].value_counts()\n",
    "        perc = df[var].value_counts(normalize=True) * 100\n",
    "        result = pd.DataFrame({\n",
    "            'Frequency': freq,\n",
    "            'Percentage (%)': perc.round(1)\n",
    "        })\n",
    "        print(f\"\\n{var}:\")\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Kolmogorov-Smirnov test for normality\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "scale_vars = ['DSS_Personal', 'DSS_Perceived', 'DSS_Total', 'ATSPPHS_Openness', 'ATSPPHS_Value', 'ATSPPHS_Total']\n",
    "\n",
    "print(\"\\nKolmogorov-Smirnov Normality Test Results:\")\n",
    "for var in scale_vars:\n",
    "    if var in df_numeric.columns:\n",
    "        # Remove any NaN values\n",
    "        data = df_numeric[var].dropna()\n",
    "        \n",
    "        # Only perform test if we have data\n",
    "        if len(data) > 0:\n",
    "            # Calculate mean and std for the data\n",
    "            mean = data.mean()\n",
    "            std = data.std()\n",
    "            \n",
    "            # Perform the test\n",
    "            stat, p = stats.kstest(data, 'norm', args=(mean, std))\n",
    "            \n",
    "            print(f\"{var}: Statistic={stat:.4f}, p-value={p:.4f}, Normal distribution: {p > 0.05}\")\n",
    "        else:\n",
    "            print(f\"{var}: Not enough data for normality test\")\n",
    "    else:\n",
    "        print(f\"{var}: Not found in dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary variables for the scales based on median split\n",
    "# This is an alternative to dichotomizing each individual item\n",
    "\n",
    "# For DSS scales, higher scores indicate more stigma\n",
    "df_numeric['DSS_Personal_High'] = (df_numeric['DSS_Personal'] > df_numeric['DSS_Personal'].median()).astype(int)\n",
    "df_numeric['DSS_Perceived_High'] = (df_numeric['DSS_Perceived'] > df_numeric['DSS_Perceived'].median()).astype(int)\n",
    "df_numeric['DSS_Total_High'] = (df_numeric['DSS_Total'] > df_numeric['DSS_Total'].median()).astype(int)\n",
    "\n",
    "# For ATSPPHS scales, higher scores indicate more positive attitude\n",
    "df_numeric['ATSPPHS_Openness_High'] = (df_numeric['ATSPPHS_Openness'] > df_numeric['ATSPPHS_Openness'].median()).astype(int)\n",
    "df_numeric['ATSPPHS_Value_High'] = (df_numeric['ATSPPHS_Value'] > df_numeric['ATSPPHS_Value'].median()).astype(int)\n",
    "df_numeric['ATSPPHS_Total_High'] = (df_numeric['ATSPPHS_Total'] > df_numeric['ATSPPHS_Total'].median()).astype(int)\n",
    "\n",
    "# Display frequencies of high/low categories\n",
    "print(\"\\nFrequencies of Dichotomized Scale Scores:\")\n",
    "binary_vars = ['DSS_Personal_High', 'DSS_Perceived_High', 'DSS_Total_High', \n",
    "               'ATSPPHS_Openness_High', 'ATSPPHS_Value_High', 'ATSPPHS_Total_High']\n",
    "\n",
    "for var in binary_vars:\n",
    "    freq = df_numeric[var].value_counts()\n",
    "    perc = df_numeric[var].value_counts(normalize=True) * 100\n",
    "    result = pd.DataFrame({\n",
    "        'Frequency': freq,\n",
    "        'Percentage (%)': perc.round(1)\n",
    "    })\n",
    "    print(f\"\\n{var}:\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-Square test for categorical variables and dichotomized scales\n",
    "# Example: Test association between Gender and DSS_Personal_High\n",
    "if 'Gender' in df.columns and 'DSS_Personal_High' in df_numeric.columns:\n",
    "    # Create a contingency table\n",
    "    contingency_table = pd.crosstab(df['Gender'], df_numeric['DSS_Personal_High'])\n",
    "    print(\"\\nContingency Table (Gender vs DSS_Personal_High):\")\n",
    "    print(contingency_table)\n",
    "    \n",
    "    # Perform Chi-Square test\n",
    "    chi2, p, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "    \n",
    "    # Check if Fisher's exact test is needed (if any expected frequency < 5)\n",
    "    if (expected < 5).any():\n",
    "        print(\"\\nUsing Fisher's exact test (expected frequency < 5)\")\n",
    "        odds_ratio, p = stats.fisher_exact(contingency_table)\n",
    "        test_name = \"Fisher's exact test\"\n",
    "    else:\n",
    "        print(\"\\nUsing Chi-Square test\")\n",
    "        test_name = \"Chi-Square test\"\n",
    "    \n",
    "    print(f\"\\n{test_name} results:\")\n",
    "    print(f\"p-value: {p:.4f}\")\n",
    "    print(f\"Significant (p ≤ 0.05): {p <= 0.05}\")\n",
    "else:\n",
    "    print(\"\\nCannot perform Gender vs DSS_Personal_High test - columns not found\")\n",
    "\n",
    "# Example: Test association between Living arrangement and ATSPPHS_Total_High\n",
    "if 'Living arrangement' in df.columns and 'ATSPPHS_Total_High' in df_numeric.columns:\n",
    "    # Create a contingency table\n",
    "    contingency_table = pd.crosstab(df['Living arrangement'], df_numeric['ATSPPHS_Total_High'])\n",
    "    print(\"\\nContingency Table (Living arrangement vs ATSPPHS_Total_High):\")\n",
    "    print(contingency_table)\n",
    "    \n",
    "    # Perform Chi-Square test\n",
    "    chi2, p, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "    \n",
    "    # Check if Fisher's exact test is needed (if any expected frequency < 5)\n",
    "    if (expected < 5).any():\n",
    "        print(\"\\nUsing Fisher's exact test (expected frequency < 5)\")\n",
    "        # For tables larger than 2x2, we might need a different approach\n",
    "        if contingency_table.shape == (2, 2):\n",
    "            odds_ratio, p = stats.fisher_exact(contingency_table)\n",
    "        else:\n",
    "            print(\"Table is larger than 2x2, p-value from Chi-Square may not be accurate\")\n",
    "        test_name = \"Fisher's exact test\"\n",
    "    else:\n",
    "        print(\"\\nUsing Chi-Square test\")\n",
    "        test_name = \"Chi-Square test\"\n",
    "    \n",
    "    print(f\"\\n{test_name} results:\")\n",
    "    print(f\"p-value: {p:.4f}\")\n",
    "    print(f\"Significant (p ≤ 0.05): {p <= 0.05}\")\n",
    "else:\n",
    "    print(\"\\nCannot perform Living arrangement vs ATSPPHS_Total_High test - columns not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types of variables used in regression\n",
    "X_vars = ['Age', 'DSS_Personal', 'DSS_Perceived']\n",
    "cat_vars = ['Gender', 'Living arrangement', 'Depression']\n",
    "\n",
    "print(\"Data types of regression variables:\")\n",
    "for var in X_vars + cat_vars:\n",
    "    if var in df_numeric.columns:\n",
    "        print(f\"{var}: {df_numeric[var].dtype}\")\n",
    "    else:\n",
    "        print(f\"{var}: Not in dataframe\")\n",
    "\n",
    "# Let's examine if there are any non-numeric values in our continuous variables\n",
    "for var in X_vars:\n",
    "    if var in df_numeric.columns:\n",
    "        non_numeric = df_numeric[var][~pd.to_numeric(df_numeric[var], errors='coerce').notna()]\n",
    "        if len(non_numeric) > 0:\n",
    "            print(f\"\\nNon-numeric values in {var}:\")\n",
    "            print(non_numeric)\n",
    "\n",
    "# Now let's fix the regression model by ensuring all variables are numeric\n",
    "# Prepare data properly for regression\n",
    "def prepare_regression_data(df, dep_var, indep_vars, cat_vars):\n",
    "    # Create a clean dataframe for regression\n",
    "    df_reg = df.copy()\n",
    "    \n",
    "    # Ensure all numeric variables are properly converted\n",
    "    for var in indep_vars + [dep_var]:\n",
    "        if var in df_reg.columns:\n",
    "            df_reg[var] = pd.to_numeric(df_reg[var], errors='coerce')\n",
    "    \n",
    "    # Drop rows with NaN in dependent or independent variables\n",
    "    df_reg = df_reg.dropna(subset=indep_vars + [dep_var])\n",
    "    \n",
    "    # Select continuous variables for the model\n",
    "    X = df_reg[indep_vars].copy()\n",
    "    \n",
    "    # Add dummy variables for categorical predictors\n",
    "    for cat_var in cat_vars:\n",
    "        if cat_var in df_reg.columns:\n",
    "            if cat_var == 'Gender':\n",
    "                # Gender (reference: Female)\n",
    "                X[f'{cat_var}_Male'] = (df_reg[cat_var] == 'Male').astype(int)\n",
    "            elif cat_var == 'Depression':\n",
    "                # Depression (reference: no)\n",
    "                X[f'{cat_var}_yes'] = (df_reg[cat_var] == 'yes').astype(int)\n",
    "            else:\n",
    "                # Other categorical variables (reference: first category)\n",
    "                dummies = pd.get_dummies(df_reg[cat_var], prefix=cat_var, drop_first=True)\n",
    "                X = pd.concat([X, dummies], axis=1)\n",
    "    \n",
    "    # Add constant\n",
    "    X = sm.add_constant(X)\n",
    "    \n",
    "    # Define dependent variable\n",
    "    y = df_reg[dep_var]\n",
    "    \n",
    "    return X, y, df_reg\n",
    "\n",
    "# Run the regression for ATSPPHS_Total\n",
    "dep_var = 'ATSPPHS_Total'\n",
    "indep_vars = ['Age', 'DSS_Personal', 'DSS_Perceived']\n",
    "cat_vars = ['Gender', 'Living arrangement', 'Depression']\n",
    "\n",
    "try:\n",
    "    X, y, df_reg = prepare_regression_data(df_numeric, dep_var, indep_vars, cat_vars)\n",
    "    \n",
    "    # Print information about the data\n",
    "    print(f\"\\nRegression data shapes: X: {X.shape}, y: {y.shape}\")\n",
    "    print(f\"X data types:\\n{X.dtypes}\")\n",
    "    \n",
    "    # Fit the model\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    # Display regression results\n",
    "    print(\"\\nMultiple Linear Regression: Predictors of ATSPPHS_Total\")\n",
    "    print(model.summary())\n",
    "    \n",
    "    # Extract coefficients and confidence intervals\n",
    "    coefs = model.params\n",
    "    conf_int = model.conf_int(alpha=0.05)\n",
    "    std_err = model.bse\n",
    "    p_values = model.pvalues\n",
    "    \n",
    "    # Create a dataframe for regression results\n",
    "    results_df = pd.DataFrame({\n",
    "        'Coefficient': coefs,\n",
    "        'Std. Error': std_err,\n",
    "        'p-value': p_values,\n",
    "        '95% CI Lower': conf_int[0],\n",
    "        '95% CI Upper': conf_int[1],\n",
    "        'Significant': p_values <= 0.05\n",
    "    })\n",
    "    \n",
    "    print(\"\\nRegression Coefficients with 95% Confidence Intervals:\")\n",
    "    print(results_df)\n",
    "except Exception as e:\n",
    "    print(f\"Error in regression: {e}\")\n",
    "    print(\"\\nChecking for problematic columns:\")\n",
    "    # Find problematic columns with object dtype\n",
    "    object_cols = X.select_dtypes(include=['object']).columns\n",
    "    if len(object_cols) > 0:\n",
    "        print(f\"Columns with object dtype: {object_cols.tolist()}\")\n",
    "        for col in object_cols:\n",
    "            print(f\"\\nUnique values in {col}:\")\n",
    "            print(X[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the regression model specifically addressing the boolean column\n",
    "dep_var = 'ATSPPHS_Total'\n",
    "indep_vars = ['Age', 'DSS_Personal', 'DSS_Perceived']\n",
    "cat_vars = ['Gender', 'Living arrangement', 'Depression']\n",
    "\n",
    "# Create a clean dataframe for regression\n",
    "df_reg = df_numeric.copy()\n",
    "\n",
    "# Ensure all numeric variables are properly converted\n",
    "for var in indep_vars + [dep_var]:\n",
    "    if var in df_reg.columns:\n",
    "        df_reg[var] = pd.to_numeric(df_reg[var], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN in dependent or independent variables\n",
    "df_reg = df_reg.dropna(subset=indep_vars + [dep_var])\n",
    "\n",
    "# Create X matrix manually to ensure all columns are numeric\n",
    "X = pd.DataFrame()\n",
    "X['const'] = 1.0\n",
    "X['Age'] = df_reg['Age'].astype(float)\n",
    "X['DSS_Personal'] = df_reg['DSS_Personal'].astype(float)\n",
    "X['DSS_Perceived'] = df_reg['DSS_Perceived'].astype(float)\n",
    "\n",
    "# Add dummy variables manually\n",
    "X['Gender_Male'] = (df_reg['Gender'] == 'Male').astype(float)\n",
    "\n",
    "# Create living arrangement dummies\n",
    "# First, get the unique values\n",
    "living_categories = df_reg['Living arrangement'].unique()\n",
    "if len(living_categories) > 1:\n",
    "    # Use the first category as reference\n",
    "    reference_category = living_categories[0]\n",
    "    for category in living_categories[1:]:\n",
    "        # Create dummy variable for each non-reference category\n",
    "        X[f'Living_{category}'] = (df_reg['Living arrangement'] == category).astype(float)\n",
    "\n",
    "# Add Depression dummy\n",
    "X['Depression_yes'] = (df_reg['Depression'] == 'yes').astype(float)\n",
    "\n",
    "# Define dependent variable\n",
    "y = df_reg[dep_var].astype(float)\n",
    "\n",
    "# Check data types\n",
    "print(\"X data types after manual conversion:\")\n",
    "print(X.dtypes)\n",
    "\n",
    "# Fit the model\n",
    "try:\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    # Display regression results\n",
    "    print(\"\\nMultiple Linear Regression: Predictors of ATSPPHS_Total\")\n",
    "    print(model.summary())\n",
    "    \n",
    "    # Extract coefficients and confidence intervals\n",
    "    coefs = model.params\n",
    "    conf_int = model.conf_int(alpha=0.05)\n",
    "    std_err = model.bse\n",
    "    p_values = model.pvalues\n",
    "    \n",
    "    # Create a dataframe for regression results\n",
    "    results_df = pd.DataFrame({\n",
    "        'Coefficient': coefs,\n",
    "        'Std. Error': std_err,\n",
    "        'p-value': p_values,\n",
    "        '95% CI Lower': conf_int[0],\n",
    "        '95% CI Upper': conf_int[1],\n",
    "        'Significant': p_values <= 0.05\n",
    "    })\n",
    "    \n",
    "    print(\"\\nRegression Coefficients with 95% Confidence Intervals:\")\n",
    "    print(results_df)\n",
    "except Exception as e:\n",
    "    print(f\"Error in regression: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the regression model by removing inf/nan values\n",
    "dep_var = 'ATSPPHS_Total'\n",
    "indep_vars = ['Age', 'DSS_Personal', 'DSS_Perceived']\n",
    "cat_vars = ['Gender', 'Living arrangement', 'Depression']\n",
    "\n",
    "# Create a clean dataframe for regression\n",
    "df_reg = df_numeric.copy()\n",
    "\n",
    "# Ensure all numeric variables are properly converted\n",
    "for var in indep_vars + [dep_var]:\n",
    "    if var in df_reg.columns:\n",
    "        df_reg[var] = pd.to_numeric(df_reg[var], errors='coerce')\n",
    "\n",
    "# Create X matrix manually to ensure all columns are numeric\n",
    "X = pd.DataFrame()\n",
    "X['const'] = 1.0\n",
    "X['Age'] = df_reg['Age'].astype(float)\n",
    "X['DSS_Personal'] = df_reg['DSS_Personal'].astype(float)\n",
    "X['DSS_Perceived'] = df_reg['DSS_Perceived'].astype(float)\n",
    "\n",
    "# Add dummy variables manually\n",
    "X['Gender_Male'] = (df_reg['Gender'] == 'Male').astype(float)\n",
    "\n",
    "# Create living arrangement dummies\n",
    "# First, get the unique values\n",
    "living_categories = df_reg['Living arrangement'].unique()\n",
    "if len(living_categories) > 1:\n",
    "    # Use the first category as reference\n",
    "    reference_category = living_categories[0]\n",
    "    for category in living_categories[1:]:\n",
    "        # Create dummy variable for each non-reference category\n",
    "        X[f'Living_{category}'] = (df_reg['Living arrangement'] == category).astype(float)\n",
    "\n",
    "# Add Depression dummy\n",
    "X['Depression_yes'] = (df_reg['Depression'] == 'yes').astype(float)\n",
    "\n",
    "# Define dependent variable\n",
    "y = df_reg[dep_var].astype(float)\n",
    "\n",
    "# Check for NaN or infinite values\n",
    "print(\"Checking for NaN or inf values in predictor variables:\")\n",
    "for col in X.columns:\n",
    "    nan_count = X[col].isna().sum()\n",
    "    inf_count = np.isinf(X[col]).sum()\n",
    "    if nan_count > 0 or inf_count > 0:\n",
    "        print(f\"{col}: {nan_count} NaNs, {inf_count} infs\")\n",
    "\n",
    "# Drop rows with NaN or inf values\n",
    "mask_finite = np.isfinite(X).all(axis=1) & np.isfinite(y)\n",
    "X_clean = X[mask_finite]\n",
    "y_clean = y[mask_finite]\n",
    "\n",
    "print(f\"\\nRemoved {len(X) - len(X_clean)} rows with NaN/inf values\")\n",
    "print(f\"Final regression data shapes: X: {X_clean.shape}, y: {y_clean.shape}\")\n",
    "\n",
    "# Fit the model\n",
    "try:\n",
    "    model = sm.OLS(y_clean, X_clean).fit()\n",
    "    \n",
    "    # Display regression results\n",
    "    print(\"\\nMultiple Linear Regression: Predictors of ATSPPHS_Total\")\n",
    "    print(model.summary())\n",
    "    \n",
    "    # Extract coefficients and confidence intervals\n",
    "    coefs = model.params\n",
    "    conf_int = model.conf_int(alpha=0.05)\n",
    "    std_err = model.bse\n",
    "    p_values = model.pvalues\n",
    "    \n",
    "    # Create a dataframe for regression results\n",
    "    results_df = pd.DataFrame({\n",
    "        'Coefficient': coefs,\n",
    "        'Std. Error': std_err,\n",
    "        'p-value': p_values,\n",
    "        '95% CI Lower': conf_int[0],\n",
    "        '95% CI Upper': conf_int[1],\n",
    "        'Significant': p_values <= 0.05\n",
    "    })\n",
    "    \n",
    "    print(\"\\nRegression Coefficients with 95% Confidence Intervals:\")\n",
    "    print(results_df)\n",
    "except Exception as e:\n",
    "    print(f\"Error in regression: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the regression model by properly creating the const column\n",
    "dep_var = 'ATSPPHS_Total'\n",
    "indep_vars = ['Age', 'DSS_Personal', 'DSS_Perceived']\n",
    "cat_vars = ['Gender', 'Living arrangement', 'Depression']\n",
    "\n",
    "# Create a clean dataframe for regression\n",
    "df_reg = df_numeric.copy()\n",
    "\n",
    "# Ensure all numeric variables are properly converted\n",
    "for var in indep_vars + [dep_var]:\n",
    "    if var in df_reg.columns:\n",
    "        df_reg[var] = pd.to_numeric(df_reg[var], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN in dependent or independent variables\n",
    "mask = df_reg[indep_vars + [dep_var]].notna().all(axis=1)\n",
    "df_reg = df_reg[mask]\n",
    "\n",
    "print(f\"Kept {len(df_reg)} rows after removing NaN values in key variables\")\n",
    "\n",
    "# Create X matrix manually to ensure all columns are numeric\n",
    "X = pd.DataFrame()\n",
    "X['const'] = np.ones(len(df_reg))  # Correctly create the constant column\n",
    "X['Age'] = df_reg['Age'].astype(float)\n",
    "X['DSS_Personal'] = df_reg['DSS_Personal'].astype(float)\n",
    "X['DSS_Perceived'] = df_reg['DSS_Perceived'].astype(float)\n",
    "\n",
    "# Add dummy variables manually\n",
    "X['Gender_Male'] = (df_reg['Gender'] == 'Male').astype(float)\n",
    "\n",
    "# Create living arrangement dummies\n",
    "# First, get the unique values\n",
    "living_categories = df_reg['Living arrangement'].unique()\n",
    "if len(living_categories) > 1:\n",
    "    # Use the first category as reference\n",
    "    reference_category = living_categories[0]\n",
    "    for category in living_categories[1:]:\n",
    "        # Create dummy variable for each non-reference category\n",
    "        X[f'Living_{category}'] = (df_reg['Living arrangement'] == category).astype(float)\n",
    "\n",
    "# Add Depression dummy\n",
    "X['Depression_yes'] = (df_reg['Depression'] == 'yes').astype(float)\n",
    "\n",
    "# Define dependent variable\n",
    "y = df_reg[dep_var].astype(float)\n",
    "\n",
    "print(f\"Final regression data shapes: X: {X.shape}, y: {y.shape}\")\n",
    "\n",
    "# Check if we have enough data\n",
    "if len(X) > 0:\n",
    "    # Fit the model\n",
    "    try:\n",
    "        model = sm.OLS(y, X).fit()\n",
    "        \n",
    "        # Display regression results\n",
    "        print(\"\\nMultiple Linear Regression: Predictors of ATSPPHS_Total\")\n",
    "        print(model.summary())\n",
    "        \n",
    "        # Extract coefficients and confidence intervals\n",
    "        coefs = model.params\n",
    "        conf_int = model.conf_int(alpha=0.05)\n",
    "        std_err = model.bse\n",
    "        p_values = model.pvalues\n",
    "        \n",
    "        # Create a dataframe for regression results\n",
    "        results_df = pd.DataFrame({\n",
    "            'Coefficient': coefs,\n",
    "            'Std. Error': std_err,\n",
    "            'p-value': p_values,\n",
    "            '95% CI Lower': conf_int[0],\n",
    "            '95% CI Upper': conf_int[1],\n",
    "            'Significant': p_values <= 0.05\n",
    "        })\n",
    "        \n",
    "        print(\"\\nRegression Coefficients with 95% Confidence Intervals:\")\n",
    "        print(results_df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in regression: {e}\")\n",
    "else:\n",
    "    print(\"No data available for regression after filtering out NaN values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to generate the demographic characteristics table\n",
    "# First, calculate frequency and percentages for categorical variables\n",
    "demographic_vars = {\n",
    "    'Gender': df['Gender'].value_counts(),\n",
    "    'Living arrangement': df['Living arrangement'].value_counts(),\n",
    "    'Marital status': df['Marital status'].value_counts(),\n",
    "    'Family system': df['Family system'].value_counts(),\n",
    "    'History of suicide in family': df['History of suicide in family'].value_counts(),\n",
    "    'Depression': df['Depression'].value_counts(),\n",
    "    'Field of Study': df['Field of Study'].value_counts()\n",
    "}\n",
    "\n",
    "# Create a DataFrame for the demographics table\n",
    "demographics_table = pd.DataFrame(columns=['Characteristics', 'n (%)'])\n",
    "\n",
    "# Add age row\n",
    "age_row = pd.DataFrame({\n",
    "    'Characteristics': ['Age in years, mean (SD)'],\n",
    "    'n (%)': [f\"{df_numeric['Age'].mean():.2f} ± {df_numeric['Age'].std():.2f}\"]\n",
    "})\n",
    "demographics_table = pd.concat([demographics_table, age_row], ignore_index=True)\n",
    "\n",
    "# Add other demographic variables\n",
    "for var, counts in demographic_vars.items():\n",
    "    for category, count in counts.items():\n",
    "        percentage = count / len(df) * 100\n",
    "        row = pd.DataFrame({\n",
    "            'Characteristics': [f\"{var}: {category}\"],\n",
    "            'n (%)': [f\"{count} ({percentage:.1f}%)\"]\n",
    "        })\n",
    "        demographics_table = pd.concat([demographics_table, row], ignore_index=True)\n",
    "\n",
    "print(\"Table 1: Demographic characteristics of participants (n=199)\")\n",
    "print(demographics_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to generate scale score comparison table\n",
    "# We'll compare Medicine/Nursing vs Other Fields\n",
    "# First, create a field grouping\n",
    "df_numeric['Field_Group'] = df['Field of Study'].apply(\n",
    "    lambda x: 'Medicine/Nursing' if x == 'Medicine/ Nursing' else 'Other Fields'\n",
    ")\n",
    "\n",
    "# Calculate mean and SD for each scale by field group\n",
    "scales = ['ATSPPHS_Openness', 'ATSPPHS_Value', 'ATSPPHS_Total', \n",
    "          'DSS_Personal', 'DSS_Perceived', 'DSS_Total']\n",
    "\n",
    "# Create an empty DataFrame for the scale scores table\n",
    "scale_table = pd.DataFrame(columns=['Characteristics', 'Total', 'Medicine/Nursing', 'Other Fields', 'p-value'])\n",
    "\n",
    "# Add rows for each scale\n",
    "for scale in scales:\n",
    "    # Calculate overall mean and SD\n",
    "    total_mean = df_numeric[scale].mean()\n",
    "    total_sd = df_numeric[scale].std()\n",
    "    \n",
    "    # Calculate mean and SD for Medicine/Nursing\n",
    "    med_data = df_numeric[df_numeric['Field_Group'] == 'Medicine/Nursing'][scale]\n",
    "    med_mean = med_data.mean()\n",
    "    med_sd = med_data.std()\n",
    "    \n",
    "    # Calculate mean and SD for Other Fields\n",
    "    other_data = df_numeric[df_numeric['Field_Group'] == 'Other Fields'][scale]\n",
    "    other_mean = other_data.mean()\n",
    "    other_sd = other_data.std()\n",
    "    \n",
    "    # Calculate p-value for difference between groups\n",
    "    _, p_val = stats.ttest_ind(med_data, other_data, equal_var=False)\n",
    "    \n",
    "    # Create a row for this scale\n",
    "    row = pd.DataFrame({\n",
    "        'Characteristics': [scale],\n",
    "        'Total': [f\"{total_mean:.2f} ± {total_sd:.2f}\"],\n",
    "        'Medicine/Nursing': [f\"{med_mean:.2f} ± {med_sd:.2f}\"],\n",
    "        'Other Fields': [f\"{other_mean:.2f} ± {other_sd:.2f}\"],\n",
    "        'p-value': [f\"{p_val:.3f}\"]\n",
    "    })\n",
    "    \n",
    "    # Add row to table\n",
    "    scale_table = pd.concat([scale_table, row], ignore_index=True)\n",
    "\n",
    "print(\"Table 3: Comparison of ATSPPHS and DSS scale scores by field of study\")\n",
    "print(scale_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to generate ATSPPHS item distribution table\n",
    "# First, identify agreement and disagreement values\n",
    "agree_values = ['Strongly agree', 'Strongly Agree', 'Agree']\n",
    "disagree_values = ['Strongly Disagree', 'Disagree']\n",
    "\n",
    "# Separate openness and value items\n",
    "openness_items = exact_atspphs_openness\n",
    "value_items = exact_atspphs_value\n",
    "\n",
    "# Create an empty DataFrame for the ATSPPHS table\n",
    "atspphs_table = pd.DataFrame(columns=['S.No', 'Items', 'Agree n (%)', 'Disagree n (%)', 'p-value'])\n",
    "\n",
    "# Add rows for Openness Scale items\n",
    "for i, item in enumerate(openness_items, 1):\n",
    "    # Calculate overall agreement/disagreement\n",
    "    agree_count = df[item].isin(agree_values).sum()\n",
    "    disagree_count = df[item].isin(disagree_values).sum()\n",
    "    agree_pct = agree_count / len(df) * 100\n",
    "    disagree_pct = disagree_count / len(df) * 100\n",
    "    \n",
    "    # Calculate p-value between field groups\n",
    "    med_agree = df[df['Field of Study'] == 'Medicine/ Nursing'][item].isin(agree_values).sum()\n",
    "    med_disagree = df[df['Field of Study'] == 'Medicine/ Nursing'][item].isin(disagree_values).sum()\n",
    "    other_agree = agree_count - med_agree\n",
    "    other_disagree = disagree_count - med_disagree\n",
    "    \n",
    "    contingency = np.array([[med_agree, med_disagree], [other_agree, other_disagree]])\n",
    "    _, p_val, _, _ = stats.chi2_contingency(contingency)\n",
    "    \n",
    "    # Create a row for this item\n",
    "    item_name = item\n",
    "    if len(item_name) > 50:  # Truncate long item names\n",
    "        item_name = item_name[:47] + \"...\"\n",
    "        \n",
    "    row = pd.DataFrame({\n",
    "        'S.No': [i],\n",
    "        'Items': [item_name],\n",
    "        'Agree n (%)': [f\"{agree_count} ({agree_pct:.1f}%)\"],\n",
    "        'Disagree n (%)': [f\"{disagree_count} ({disagree_pct:.1f}%)\"],\n",
    "        'p-value': [f\"{p_val:.3f}\"]\n",
    "    })\n",
    "    \n",
    "    # Add row to table\n",
    "    atspphs_table = pd.concat([atspphs_table, row], ignore_index=True)\n",
    "\n",
    "# Add a section header for Openness Scale\n",
    "header_row = pd.DataFrame({\n",
    "    'S.No': [\"\"],\n",
    "    'Items': [\"Openness Scale\"],\n",
    "    'Agree n (%)': [\"\"],\n",
    "    'Disagree n (%)': [\"\"],\n",
    "    'p-value': [\"\"]\n",
    "})\n",
    "atspphs_table = pd.concat([header_row, atspphs_table], ignore_index=True)\n",
    "\n",
    "# Add rows for Value Scale items\n",
    "value_table = pd.DataFrame(columns=['S.No', 'Items', 'Agree n (%)', 'Disagree n (%)', 'p-value'])\n",
    "for i, item in enumerate(value_items, 1):\n",
    "    # Calculate overall agreement/disagreement\n",
    "    agree_count = df[item].isin(agree_values).sum()\n",
    "    disagree_count = df[item].isin(disagree_values).sum()\n",
    "    agree_pct = agree_count / len(df) * 100\n",
    "    disagree_pct = disagree_count / len(df) * 100\n",
    "    \n",
    "    # Calculate p-value between field groups\n",
    "    med_agree = df[df['Field of Study'] == 'Medicine/ Nursing'][item].isin(agree_values).sum()\n",
    "    med_disagree = df[df['Field of Study'] == 'Medicine/ Nursing'][item].isin(disagree_values).sum()\n",
    "    other_agree = agree_count - med_agree\n",
    "    other_disagree = disagree_count - med_disagree\n",
    "    \n",
    "    contingency = np.array([[med_agree, med_disagree], [other_agree, other_disagree]])\n",
    "    _, p_val, _, _ = stats.chi2_contingency(contingency)\n",
    "    \n",
    "    # Create a row for this item\n",
    "    item_name = item\n",
    "    if len(item_name) > 50:  # Truncate long item names\n",
    "        item_name = item_name[:47] + \"...\"\n",
    "        \n",
    "    row = pd.DataFrame({\n",
    "        'S.No': [i],\n",
    "        'Items': [item_name],\n",
    "        'Agree n (%)': [f\"{agree_count} ({agree_pct:.1f}%)\"],\n",
    "        'Disagree n (%)': [f\"{disagree_count} ({disagree_pct:.1f}%)\"],\n",
    "        'p-value': [f\"{p_val:.3f}\"]\n",
    "    })\n",
    "    \n",
    "    # Add row to table\n",
    "    value_table = pd.concat([value_table, row], ignore_index=True)\n",
    "\n",
    "# Add a section header for Value Scale\n",
    "header_row = pd.DataFrame({\n",
    "    'S.No': [\"\"],\n",
    "    'Items': [\"Value Scale\"],\n",
    "    'Agree n (%)': [\"\"],\n",
    "    'Disagree n (%)': [\"\"],\n",
    "    'p-value': [\"\"]\n",
    "})\n",
    "value_table = pd.concat([header_row, value_table], ignore_index=True)\n",
    "\n",
    "# Combine openness and value tables\n",
    "atspphs_table = pd.concat([atspphs_table, value_table], ignore_index=True)\n",
    "\n",
    "print(\"Table 4: Distribution of ATSPPHS items (agreement vs. disagreement)\")\n",
    "print(atspphs_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to generate DSS item distribution table\n",
    "agree_values = ['Strongly agree', 'Strongly Agree', 'Agree']\n",
    "disagree_values = ['Strongly Disagree', 'Disagree']\n",
    "\n",
    "# Separate personal and perceived stigma items\n",
    "personal_items = exact_dss_personal\n",
    "perceived_items = exact_dss_perceived\n",
    "\n",
    "# Create an empty DataFrame for the DSS table\n",
    "dss_table = pd.DataFrame(columns=['S.No', 'Items', 'Agree n (%)', 'Disagree n (%)', 'p-value'])\n",
    "\n",
    "# Add rows for Personal Stigma Scale items\n",
    "for i, item in enumerate(personal_items, 1):\n",
    "    # Calculate overall agreement/disagreement\n",
    "    agree_count = df[item].isin(agree_values).sum()\n",
    "    disagree_count = df[item].isin(disagree_values).sum()\n",
    "    agree_pct = agree_count / len(df) * 100\n",
    "    disagree_pct = disagree_count / len(df) * 100\n",
    "    \n",
    "    # Calculate p-value between field groups\n",
    "    med_agree = df[df['Field of Study'] == 'Medicine/ Nursing'][item].isin(agree_values).sum()\n",
    "    med_disagree = df[df['Field of Study'] == 'Medicine/ Nursing'][item].isin(disagree_values).sum()\n",
    "    other_agree = agree_count - med_agree\n",
    "    other_disagree = disagree_count - med_disagree\n",
    "    \n",
    "    contingency = np.array([[med_agree, med_disagree], [other_agree, other_disagree]])\n",
    "    _, p_val, _, _ = stats.chi2_contingency(contingency)\n",
    "    \n",
    "    # Create a row for this item\n",
    "    item_name = item\n",
    "    if len(item_name) > 50:  # Truncate long item names\n",
    "        item_name = item_name[:47] + \"...\"\n",
    "        \n",
    "    row = pd.DataFrame({\n",
    "        'S.No': [i],\n",
    "        'Items': [item_name],\n",
    "        'Agree n (%)': [f\"{agree_count} ({agree_pct:.1f}%)\"],\n",
    "        'Disagree n (%)': [f\"{disagree_count} ({disagree_pct:.1f}%)\"],\n",
    "        'p-value': [f\"{p_val:.3f}\"]\n",
    "    })\n",
    "    \n",
    "    # Add row to table\n",
    "    dss_table = pd.concat([dss_table, row], ignore_index=True)\n",
    "\n",
    "# Add a section header for Personal Stigma Scale\n",
    "header_row = pd.DataFrame({\n",
    "    'S.No': [\"\"],\n",
    "    'Items': [\"Personal Stigma Scale\"],\n",
    "    'Agree n (%)': [\"\"],\n",
    "    'Disagree n (%)': [\"\"],\n",
    "    'p-value': [\"\"]\n",
    "})\n",
    "dss_table = pd.concat([header_row, dss_table], ignore_index=True)\n",
    "\n",
    "# Add rows for Perceived Stigma Scale items\n",
    "perceived_table = pd.DataFrame(columns=['S.No', 'Items', 'Agree n (%)', 'Disagree n (%)', 'p-value'])\n",
    "for i, item in enumerate(perceived_items, 1):\n",
    "    # Calculate overall agreement/disagreement\n",
    "    agree_count = df[item].isin(agree_values).sum()\n",
    "    disagree_count = df[item].isin(disagree_values).sum()\n",
    "    agree_pct = agree_count / len(df) * 100\n",
    "    disagree_pct = disagree_count / len(df) * 100\n",
    "    \n",
    "    # Calculate p-value between field groups\n",
    "    med_agree = df[df['Field of Study'] == 'Medicine/ Nursing'][item].isin(agree_values).sum()\n",
    "    med_disagree = df[df['Field of Study'] == 'Medicine/ Nursing'][item].isin(disagree_values).sum()\n",
    "    other_agree = agree_count - med_agree\n",
    "    other_disagree = disagree_count - med_disagree\n",
    "    \n",
    "    contingency = np.array([[med_agree, med_disagree], [other_agree, other_disagree]])\n",
    "    _, p_val, _, _ = stats.chi2_contingency(contingency)\n",
    "    \n",
    "    # Create a row for this item\n",
    "    item_name = item\n",
    "    if len(item_name) > 50:  # Truncate long item names\n",
    "        item_name = item_name[:47] + \"...\"\n",
    "        \n",
    "    row = pd.DataFrame({\n",
    "        'S.No': [i],\n",
    "        'Items': [item_name],\n",
    "        'Agree n (%)': [f\"{agree_count} ({agree_pct:.1f}%)\"],\n",
    "        'Disagree n (%)': [f\"{disagree_count} ({disagree_pct:.1f}%)\"],\n",
    "        'p-value': [f\"{p_val:.3f}\"]\n",
    "    })\n",
    "    \n",
    "    # Add row to table\n",
    "    perceived_table = pd.concat([perceived_table, row], ignore_index=True)\n",
    "\n",
    "# Add a section header for Perceived Stigma Scale\n",
    "header_row = pd.DataFrame({\n",
    "    'S.No': [\"\"],\n",
    "    'Items': [\"Perceived Stigma Scale\"],\n",
    "    'Agree n (%)': [\"\"],\n",
    "    'Disagree n (%)': [\"\"],\n",
    "    'p-value': [\"\"]\n",
    "})\n",
    "perceived_table = pd.concat([header_row, perceived_table], ignore_index=True)\n",
    "\n",
    "# Combine personal and perceived tables\n",
    "dss_table = pd.concat([dss_table, perceived_table], ignore_index=True)\n",
    "\n",
    "print(\"Table 5: Frequency (percentage) of DSS items (agreement vs. disagreement)\")\n",
    "print(dss_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to generate predictors table based on regression analysis\n",
    "# We'll use the regression results we already have for ATSPPHS_Total\n",
    "# and run new regressions for DSS_Personal and DSS_Perceived\n",
    "\n",
    "# Create a DataFrame for the predictors table\n",
    "predictors_table = pd.DataFrame(columns=['Characteristics', 'Crude β (95% CI)', 'Adjusted β (95% CI)'])\n",
    "\n",
    "# Define a function to run regression and extract results\n",
    "def run_regression(dep_var, indep_vars, cat_vars):\n",
    "    # Create X matrix\n",
    "    X = pd.DataFrame()\n",
    "    X['const'] = np.ones(len(df_numeric))\n",
    "    \n",
    "    for var in indep_vars:\n",
    "        if var in df_numeric.columns:\n",
    "            X[var] = df_numeric[var].astype(float)\n",
    "    \n",
    "    # Add categorical variables\n",
    "    for var in cat_vars:\n",
    "        if var == 'Gender':\n",
    "            X['Gender_Male'] = (df_numeric['Gender'] == 'Male').astype(float)\n",
    "        elif var == 'Living arrangement':\n",
    "            for category in df_numeric['Living arrangement'].unique():\n",
    "                if category != df_numeric['Living arrangement'].unique()[0]:  # Skip reference category\n",
    "                    X[f'Living_{category}'] = (df_numeric['Living arrangement'] == category).astype(float)\n",
    "        elif var == 'Depression':\n",
    "            X['Depression_yes'] = (df_numeric['Depression'] == 'yes').astype(float)\n",
    "        elif var == 'Field of Study':\n",
    "            for field in df_numeric['Field of Study'].unique():\n",
    "                if field != df_numeric['Field of Study'].unique()[0]:  # Skip reference category\n",
    "                    X[f'Field_{field}'] = (df_numeric['Field of Study'] == field).astype(float)\n",
    "    \n",
    "    # Define dependent variable\n",
    "    y = df_numeric[dep_var].astype(float)\n",
    "    \n",
    "    # Drop rows with NaN\n",
    "    mask = ~(X.isna().any(axis=1) | pd.isna(y))\n",
    "    X_clean = X[mask]\n",
    "    y_clean = y[mask]\n",
    "    \n",
    "    # Fit model\n",
    "    model = sm.OLS(y_clean, X_clean).fit()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Extract significant predictors for ATSPPHS_Total from our previous regression\n",
    "# Ensure the model exists and is defined\n",
    "if 'model' in locals() or 'model' in globals():\n",
    "    for var in model.params.index:\n",
    "        coef = model.params[var]\n",
    "        pval = model.pvalues[var]\n",
    "        conf_int = model.conf_int().loc[var]\n",
    "        \n",
    "        if pval <= 0.05:  # Only include significant predictors\n",
    "            var_name = var\n",
    "            if var == 'DSS_Personal':\n",
    "                var_name = 'Personal Depression Stigma'\n",
    "            elif var == 'Depression_yes':\n",
    "                var_name = 'Depression Diagnosis'\n",
    "            elif 'Living_' in var:\n",
    "                var_name = var.replace('Living_', 'Living arrangement: ')\n",
    "            \n",
    "            row = pd.DataFrame({\n",
    "                'Characteristics': [f\"Attitude towards seeking help: {var_name}\"],\n",
    "                'Crude β (95% CI)': [f\"{coef:.2f} ({conf_int[0]:.2f}, {conf_int[1]:.2f})\"],\n",
    "                'Adjusted β (95% CI)': [f\"{coef:.2f} ({conf_int[0]:.2f}, {conf_int[1]:.2f})\"]\n",
    "            })\n",
    "            predictors_table = pd.concat([predictors_table, row], ignore_index=True)\n",
    "else:\n",
    "    # If the model isn't available, run a new regression for ATSPPHS_Total\n",
    "    atspphs_model = run_regression('ATSPPHS_Total', \n",
    "                                 ['Age', 'DSS_Personal', 'DSS_Perceived'], \n",
    "                                 ['Gender', 'Living arrangement', 'Depression'])\n",
    "    \n",
    "    for var in atspphs_model.params.index:\n",
    "        coef = atspphs_model.params[var]\n",
    "        pval = atspphs_model.pvalues[var]\n",
    "        conf_int = atspphs_model.conf_int().loc[var]\n",
    "        \n",
    "        if pval <= 0.05:  # Only include significant predictors\n",
    "            var_name = var\n",
    "            if var == 'DSS_Personal':\n",
    "                var_name = 'Personal Depression Stigma'\n",
    "            elif var == 'Depression_yes':\n",
    "                var_name = 'Depression Diagnosis'\n",
    "            elif 'Living_' in var:\n",
    "                var_name = var.replace('Living_', 'Living arrangement: ')\n",
    "            \n",
    "            row = pd.DataFrame({\n",
    "                'Characteristics': [f\"Attitude towards seeking help: {var_name}\"],\n",
    "                'Crude β (95% CI)': [f\"{coef:.2f} ({conf_int[0]:.2f}, {conf_int[1]:.2f})\"],\n",
    "                'Adjusted β (95% CI)': [f\"{coef:.2f} ({conf_int[0]:.2f}, {conf_int[1]:.2f})\"]\n",
    "            })\n",
    "            predictors_table = pd.concat([predictors_table, row], ignore_index=True)\n",
    "\n",
    "# Run regression for DSS_Personal\n",
    "dss_personal_model = run_regression('DSS_Personal', \n",
    "                                  ['Age', 'ATSPPHS_Total'], \n",
    "                                  ['Gender', 'Living arrangement', 'Depression', 'Field of Study'])\n",
    "\n",
    "# Extract significant predictors for DSS_Personal\n",
    "for var in dss_personal_model.params.index:\n",
    "    coef = dss_personal_model.params[var]\n",
    "    pval = dss_personal_model.pvalues[var]\n",
    "    conf_int = dss_personal_model.conf_int().loc[var]\n",
    "    \n",
    "    if pval <= 0.05:  # Only include significant predictors\n",
    "        var_name = var\n",
    "        if var == 'ATSPPHS_Total':\n",
    "            var_name = 'Attitude Towards Seeking Help'\n",
    "        elif var == 'Depression_yes':\n",
    "            var_name = 'Depression Diagnosis'\n",
    "        elif 'Living_' in var:\n",
    "            var_name = var.replace('Living_', 'Living arrangement: ')\n",
    "        elif 'Field_' in var:\n",
    "            var_name = var.replace('Field_', 'Field of Study: ')\n",
    "        \n",
    "        row = pd.DataFrame({\n",
    "            'Characteristics': [f\"Personal depression stigma: {var_name}\"],\n",
    "            'Crude β (95% CI)': [f\"{coef:.2f} ({conf_int[0]:.2f}, {conf_int[1]:.2f})\"],\n",
    "            'Adjusted β (95% CI)': [f\"{coef:.2f} ({conf_int[0]:.2f}, {conf_int[1]:.2f})\"]\n",
    "        })\n",
    "        predictors_table = pd.concat([predictors_table, row], ignore_index=True)\n",
    "\n",
    "# Run regression for DSS_Perceived\n",
    "dss_perceived_model = run_regression('DSS_Perceived', \n",
    "                                   ['Age', 'ATSPPHS_Total'], \n",
    "                                   ['Gender', 'Living arrangement', 'Depression', 'Field of Study'])\n",
    "\n",
    "# Extract significant predictors for DSS_Perceived\n",
    "for var in dss_perceived_model.params.index:\n",
    "    coef = dss_perceived_model.params[var]\n",
    "    pval = dss_perceived_model.pvalues[var]\n",
    "    conf_int = dss_perceived_model.conf_int().loc[var]\n",
    "    \n",
    "    if pval <= 0.05:  # Only include significant predictors\n",
    "        var_name = var\n",
    "        if var == 'ATSPPHS_Total':\n",
    "            var_name = 'Attitude Towards Seeking Help'\n",
    "        elif var == 'Depression_yes':\n",
    "            var_name = 'Depression Diagnosis'\n",
    "        elif 'Living_' in var:\n",
    "            var_name = var.replace('Living_', 'Living arrangement: ')\n",
    "        elif 'Field_' in var:\n",
    "            var_name = var.replace('Field_', 'Field of Study: ')\n",
    "        \n",
    "        row = pd.DataFrame({\n",
    "            'Characteristics': [f\"Perceived depression stigma: {var_name}\"],\n",
    "            'Crude β (95% CI)': [f\"{coef:.2f} ({conf_int[0]:.2f}, {conf_int[1]:.2f})\"],\n",
    "            'Adjusted β (95% CI)': [f\"{coef:.2f} ({conf_int[0]:.2f}, {conf_int[1]:.2f})\"]\n",
    "        })\n",
    "        predictors_table = pd.concat([predictors_table, row], ignore_index=True)\n",
    "\n",
    "print(\"Table 6: Predictors of attitude towards seeking help, and personal and perceived depression stigma\")\n",
    "print(predictors_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to generate Table 2: Comparison of characteristics by field of study\n",
    "# We'll compare all three disciplines: Medicine/Nursing, Engineering/IT, and Arts/Humanities\n",
    "\n",
    "# List of characteristics to compare\n",
    "categorical_vars = ['Gender', 'Living arrangement', 'Marital status', 'Family system', \n",
    "                   'History of suicide in family', 'Depression']\n",
    "continuous_vars = ['Age']\n",
    "\n",
    "# Create an empty DataFrame for the comparison table\n",
    "comparison_table = pd.DataFrame(columns=['Characteristics', 'Medicine/Nursing', 'Engineering/IT', 'Arts/Humanities', 'p-value'])\n",
    "\n",
    "# Add rows for continuous variables (like age)\n",
    "for var in continuous_vars:\n",
    "    # Calculate statistics for each group\n",
    "    med_data = df_numeric[df['Field of Study'] == 'Medicine/ Nursing'][var]\n",
    "    eng_data = df_numeric[df['Field of Study'] == 'Engineering/ IT'][var]\n",
    "    arts_data = df_numeric[df['Field of Study'] == 'Arts/ Humanities'][var]\n",
    "    \n",
    "    # Calculate p-value using ANOVA\n",
    "    groups = [med_data.dropna(), eng_data.dropna(), arts_data.dropna()]\n",
    "    f_stat, p_val = stats.f_oneway(*groups)\n",
    "    \n",
    "    # Create a row for this variable\n",
    "    row = pd.DataFrame({\n",
    "        'Characteristics': [f\"{var} in years, mean (SD)\"],\n",
    "        'Medicine/Nursing': [f\"{med_data.mean():.1f} ± {med_data.std():.1f}\"],\n",
    "        'Engineering/IT': [f\"{eng_data.mean():.1f} ± {eng_data.std():.1f}\"],\n",
    "        'Arts/Humanities': [f\"{arts_data.mean():.1f} ± {arts_data.std():.1f}\"],\n",
    "        'p-value': [f\"{p_val:.3f}\"]\n",
    "    })\n",
    "    \n",
    "    # Add row to table\n",
    "    comparison_table = pd.concat([comparison_table, row], ignore_index=True)\n",
    "\n",
    "# Add rows for categorical variables\n",
    "for var in categorical_vars:\n",
    "    # Get the unique categories for this variable\n",
    "    categories = df[var].unique()\n",
    "    \n",
    "    for category in categories:\n",
    "        # Count occurrences in each group\n",
    "        med_count = sum((df['Field of Study'] == 'Medicine/ Nursing') & (df[var] == category))\n",
    "        med_total = sum(df['Field of Study'] == 'Medicine/ Nursing')\n",
    "        med_pct = med_count / med_total * 100\n",
    "        \n",
    "        eng_count = sum((df['Field of Study'] == 'Engineering/ IT') & (df[var] == category))\n",
    "        eng_total = sum(df['Field of Study'] == 'Engineering/ IT')\n",
    "        eng_pct = eng_count / eng_total * 100\n",
    "        \n",
    "        arts_count = sum((df['Field of Study'] == 'Arts/ Humanities') & (df[var] == category))\n",
    "        arts_total = sum(df['Field of Study'] == 'Arts/ Humanities')\n",
    "        arts_pct = arts_count / arts_total * 100\n",
    "        \n",
    "        # Create a row for this category\n",
    "        row = pd.DataFrame({\n",
    "            'Characteristics': [f\"{var}: {category}\"],\n",
    "            'Medicine/Nursing': [f\"{med_count} ({med_pct:.1f}%)\"],\n",
    "            'Engineering/IT': [f\"{eng_count} ({eng_pct:.1f}%)\"],\n",
    "            'Arts/Humanities': [f\"{arts_count} ({arts_pct:.1f}%)\"],\n",
    "            'p-value': [\"\"]  # We'll calculate p-values for the variable as a whole, not each category\n",
    "        })\n",
    "        \n",
    "        # Add row to table\n",
    "        comparison_table = pd.concat([comparison_table, row], ignore_index=True)\n",
    "    \n",
    "    # Calculate p-value for this categorical variable\n",
    "    contingency_table = pd.crosstab(df[var], df['Field of Study'])\n",
    "    \n",
    "    # Use Chi-square test\n",
    "    chi2, p_val, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "    \n",
    "    # If any expected frequency is < 5, note that Fisher's exact test would be more appropriate\n",
    "    # But for tables larger than 2x2, we'll still use Chi-square\n",
    "    test_type = \"Chi2\"\n",
    "    if (expected < 5).any():\n",
    "        test_type = \"Fisher\"\n",
    "    \n",
    "    # Update p-value in the last row for this variable\n",
    "    idx = comparison_table[comparison_table['Characteristics'].str.contains(var)].index[-1]\n",
    "    comparison_table.loc[idx, 'p-value'] = f\"{p_val:.3f}{' *' if test_type == 'Fisher' else ''}\"\n",
    "\n",
    "print(\"Table 2: Comparison of characteristics by field of study\")\n",
    "print(comparison_table)\n",
    "\n",
    "# Add footnote for Fisher's exact test\n",
    "if comparison_table['p-value'].str.contains('\\*').any():\n",
    "    print(\"\\n* Fisher's exact test would be more appropriate due to low expected frequencies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to generate the demographic characteristics table including all mental health conditions\n",
    "# First, calculate frequency and percentages for categorical variables\n",
    "demographic_vars = {\n",
    "    'Gender': df['Gender'].value_counts(),\n",
    "    'Living arrangement': df['Living arrangement'].value_counts(),\n",
    "    'Marital status': df['Marital status'].value_counts(),\n",
    "    'Family system': df['Family system'].value_counts(),\n",
    "    'History of suicide in family': df['History of suicide in family'].value_counts(),\n",
    "    'Family history of diagnosed mental illness in family': df['Family history of diagnosed mental illness in family'].value_counts()\n",
    "}\n",
    "\n",
    "# Mental health conditions\n",
    "mental_health_conditions = {\n",
    "    'Depression': df['Depression'].value_counts(),\n",
    "    'Generalized Anxiety Disorder (GAD)': df['GAD'].value_counts(),\n",
    "    'Panic Disorder': df['Panic'].value_counts(),\n",
    "    'Schizophrenia': df['Schiz'].value_counts(),\n",
    "    'Bipolar Disorder': df['Bipolar'].value_counts(),\n",
    "    'No diagnosed mental illness': df['None'].value_counts()\n",
    "}\n",
    "\n",
    "# Create a DataFrame for the demographics table\n",
    "demographics_table = pd.DataFrame(columns=['Characteristics', 'n (%)'])\n",
    "\n",
    "# Add age row\n",
    "age_row = pd.DataFrame({\n",
    "    'Characteristics': ['Age in years, mean (SD)'],\n",
    "    'n (%)': [f\"{df_numeric['Age'].mean():.2f} ± {df_numeric['Age'].std():.2f}\"]\n",
    "})\n",
    "demographics_table = pd.concat([demographics_table, age_row], ignore_index=True)\n",
    "\n",
    "# Add other demographic variables\n",
    "for var, counts in demographic_vars.items():\n",
    "    for category, count in counts.items():\n",
    "        percentage = count / len(df) * 100\n",
    "        row = pd.DataFrame({\n",
    "            'Characteristics': [f\"{var}: {category}\"],\n",
    "            'n (%)': [f\"{count} ({percentage:.1f}%)\"]\n",
    "        })\n",
    "        demographics_table = pd.concat([demographics_table, row], ignore_index=True)\n",
    "\n",
    "# Add a section header for mental health conditions\n",
    "header_row = pd.DataFrame({\n",
    "    'Characteristics': [\"Mental Health Conditions\"],\n",
    "    'n (%)': [\"\"]\n",
    "})\n",
    "demographics_table = pd.concat([demographics_table, header_row], ignore_index=True)\n",
    "\n",
    "# Add mental health conditions\n",
    "for condition, counts in mental_health_conditions.items():\n",
    "    for response, count in counts.items():\n",
    "        if response == 'yes':\n",
    "            percentage = count / len(df) * 100\n",
    "            row = pd.DataFrame({\n",
    "                'Characteristics': [f\"{condition}\"],\n",
    "                'n (%)': [f\"{count} ({percentage:.1f}%)\"]\n",
    "            })\n",
    "            demographics_table = pd.concat([demographics_table, row], ignore_index=True)\n",
    "\n",
    "print(\"Table 1: Demographic characteristics of participants (n=199)\")\n",
    "print(demographics_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Function to calculate Cronbach's alpha\n",
    "def cronbachs_alpha(items):\n",
    "    # Convert string responses to numeric if needed\n",
    "    if items.dtypes[0] == 'object':\n",
    "        le = LabelEncoder()\n",
    "        items_numeric = items.apply(lambda x: le.fit_transform(x))\n",
    "    else:\n",
    "        items_numeric = items\n",
    "        \n",
    "    # Calculate item variances and total variance\n",
    "    item_variances = items_numeric.var(axis=0)\n",
    "    total_variance = items_numeric.sum(axis=1).var()\n",
    "    \n",
    "    # Calculate Cronbach's alpha\n",
    "    n_items = items.shape[1]\n",
    "    return (n_items / (n_items - 1)) * (1 - item_variances.sum() / total_variance)\n",
    "\n",
    "# Calculate alpha for each subscale\n",
    "alpha_dss_personal = cronbachs_alpha(df[exact_dss_personal])\n",
    "alpha_dss_perceived = cronbachs_alpha(df[exact_dss_perceived])\n",
    "alpha_atspphs_openness = cronbachs_alpha(df[exact_atspphs_openness])\n",
    "alpha_atspphs_value = cronbachs_alpha(df[exact_atspphs_value])\n",
    "\n",
    "print(f\"Cronbach's alpha for DSS-Personal: {alpha_dss_personal:.3f}\")\n",
    "print(f\"Cronbach's alpha for DSS-Perceived: {alpha_dss_perceived:.3f}\")\n",
    "print(f\"Cronbach's alpha for ATSPPHS-Openness: {alpha_atspphs_openness:.3f}\")\n",
    "print(f\"Cronbach's alpha for ATSPPHS-Value: {alpha_atspphs_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from factor_analyzer import FactorAnalyzer\n",
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Combine all scale items\n",
    "all_items = exact_dss_personal + exact_dss_perceived + exact_atspphs_openness + exact_atspphs_value\n",
    "\n",
    "# Convert to numeric values if needed\n",
    "df_items = df_numeric[all_items]\n",
    "\n",
    "# Check if the data is suitable for factor analysis\n",
    "chi_square_value, p_value = calculate_bartlett_sphericity(df_items)\n",
    "print(f\"Bartlett's test of sphericity: chi² = {chi_square_value:.3f}, p = {p_value:.10f}\")\n",
    "\n",
    "# Run Harman's single factor test\n",
    "fa = FactorAnalyzer(n_factors=1, rotation=None)\n",
    "fa.fit(df_items)\n",
    "\n",
    "# Get the eigenvalues\n",
    "ev, _ = fa.get_eigenvalues()\n",
    "print(f\"Eigenvalues: {ev}\")\n",
    "\n",
    "# Calculate variance explained by a single factor\n",
    "loadings = fa.loadings_\n",
    "explained_variance = (loadings**2).sum() / len(loadings)\n",
    "print(f\"Variance explained by a single factor: {explained_variance:.2%}\")\n",
    "\n",
    "# If a single factor explains more than 50% of variance, common method bias might be a concern\n",
    "if explained_variance > 0.5:\n",
    "    print(\"WARNING: Common method bias may be present (>50% variance explained by a single factor)\")\n",
    "else:\n",
    "    print(\"Common method bias is likely not a major concern (<50% variance explained)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
